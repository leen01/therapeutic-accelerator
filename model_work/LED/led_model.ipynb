{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 02:57:38.887522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-20 02:57:41.572630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nanosecond heartbeat on server 1689821877933682809000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Collection(name=langchain_store),\n",
       " Collection(name=abstracts),\n",
       " Collection(name=fulltext),\n",
       " Collection(name=specter_abstracts)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! usr/bin/env python\n",
    "\n",
    "# setup\n",
    "\n",
    "# Base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# LLM packages\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, BioGptTokenizer, BioGptForCausalLM\n",
    "\n",
    "# Chunk context into 512  tokens\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# import tiktoken\n",
    "\n",
    "# @dask.delayed\n",
    "def token_len(text): \n",
    "    \"\"\" Get the length of tokens from text\"\"\"\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)['input_ids'][0]\n",
    "    return len(tokens)\n",
    "    \n",
    "chunk_size = 1024\n",
    "\n",
    "# create text splitters for processing the texts\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # separator = [\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \"; \"],\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = token_len\n",
    ")\n",
    "\n",
    "\n",
    "# Create embeddings function with specter model\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
    "model = AutoModel.from_pretrained('allenai/specter')\n",
    "\n",
    "from chromadb.api.types import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "class specter_ef(EmbeddingFunction):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def embed_documents(self, texts: Documents) -> Embeddings:\n",
    "        \n",
    "        text_list = [re.sub(\"\\n\", \" \", p) for p in texts]\n",
    "        texts = [re.sub(\"\\s\\s+\", \" \", t) for t in text_list]\n",
    "        \n",
    "        # embed the documents somehow\n",
    "        embeddings = []\n",
    "        \n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "            result = model(**inputs)\n",
    "            embeddings.append(result.last_hidden_state[:, 0, :])\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "specter_embeder = specter_ef(model, tokenizer)\n",
    "\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Create chroma client\n",
    "chroma = chromadb.Client(Settings(chroma_api_impl=\"rest\",\n",
    "                                  chroma_server_host=\"34.238.51.66\", # EC2 instance public IPv4\n",
    "                                  chroma_server_http_port=8000))\n",
    "\n",
    "print(\"Nanosecond heartbeat on server\", chroma.heartbeat()) # returns a nanosecond heartbeat. Useful for making sure the client remains connected.\n",
    "\n",
    "# Check Existing connections\n",
    "display(chroma.list_collections())\n",
    "\n",
    "collection = chroma.get_or_create_collection(\"specter_abstracts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = pd.read_csv('/home/ubuntu/work/therapeutic_accelerator/data/prompts.csv')\n",
    "# testing prompt one\n",
    "question = prompts.loc[0, \"Prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_embeddings(question): \n",
    "    # Embed question\n",
    "    question_embeddings = specter_embeder.embed_documents([question])[0][0].tolist()\n",
    "    \n",
    "    return question_embeddings\n",
    "\n",
    "def query_chroma(question_embeddings):\n",
    "    # Query ChromaDB with Embeddings\n",
    "    results = collection.query(\n",
    "        query_embeddings=[question_embeddings],\n",
    "        n_results=10\n",
    "        # where={\"metadata_field\": \"is_equal_to_this\"},\n",
    "        # where_document={\"$contains\":\"search_string\"}\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['38374595-0',\n",
       "   '203622768-0',\n",
       "   '234597674-0',\n",
       "   '211474643-0',\n",
       "   '11181159-0',\n",
       "   '10984456-0',\n",
       "   '232429176-0',\n",
       "   '246997767-0',\n",
       "   '240425531-0',\n",
       "   '38325820-0']],\n",
       " 'distances': [[196.53672790527344,\n",
       "   210.16175842285156,\n",
       "   224.75006103515625,\n",
       "   240.17074584960938,\n",
       "   246.17657470703125,\n",
       "   247.79898071289062,\n",
       "   263.77459716796875,\n",
       "   273.4192199707031,\n",
       "   283.67694091796875,\n",
       "   284.9610290527344]],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [[{'corpusid': 38374595, 'chunk': 0},\n",
       "   {'corpusid': 203622768, 'chunk': 0},\n",
       "   {'corpusid': 234597674, 'chunk': 0},\n",
       "   {'corpusid': 211474643, 'chunk': 0},\n",
       "   {'corpusid': 11181159, 'chunk': 0},\n",
       "   {'corpusid': 10984456, 'chunk': 0},\n",
       "   {'corpusid': 232429176, 'chunk': 0},\n",
       "   {'corpusid': 246997767, 'chunk': 0},\n",
       "   {'corpusid': 240425531, 'chunk': 0},\n",
       "   {'corpusid': 38325820, 'chunk': 0}]],\n",
       " 'documents': [['Microvascular density (MVD), a marker for tumor angiogenesis, has been demonstrated to have prognostic significance in various malignancies. Previous studies have demonstrated that MVD is an independent prognostic factor in pancreatic adenocarcinoma and that longer survival is associated with hypovascular tumors. The prognostic importance of MVD in pancreatic neuroendocrine tumor (NET) has not been documented. We evaluated MVD in pancreatic NET and correlated it with clinicopathologic features and patient outcome to determine whether MVD is a useful prognostic indicator for these patients. Twenty-five pancreatic NETs from our archival files resected between 1981 and 2000 were identified. The mean MVD was determined for each tumor from the 3 most vascularized 200 × fields. Clinical follow-up ranged from 1 to 19 years, with a mean of 4.9 years. At last follow-up, 6 patients were dead of disease, 10 patients were alive without disease, 4 patients were alive with disease, and 5 patients were alive with disease status unknown. Mean MVD ranged from 43 to 527 microvessels per 200 × field. MVD did not correlate with tumor size, the examined histologic parameters, or patient outcome. MVD in pancreatic NET does not correlate with the clinicohistologic features evaluated in this study or with the patient outcome and is not a useful prognostic indicator in these patients. These results suggest that factors other than the simple number of microvessels are important in determining pancreatic NET behavior. However, most tumors were highly vascular, and additional studies may be helpful to clarify further the role of vascularity and assess the utility of antiangiogenic agents in the treatment of pancreatic NET.',\n",
       "   'Background/Aim: This study aimed to identify risk factors for recurrence of patients with stage III colorectal cancer by assessing clinicopathological features. Patients and Methods: The study included 231 patients with stage III colorectal cancer who underwent curative resection between 2006 and 2012 at the Department of Surgery of the Jikei University Hospital, Tokyo, Japan. Clinicopathological data of the patients were retrospectively evaluated. Results: The recurrence rate was 27.7% (64/231) in the study group. The univariate analysis for recurrence identified five risk factors: site of primary tumor (rectal cancer), surgical procedure (open surgery), preoperative serum CEA level (>5 ng/ml), preoperative serum CA19-9 level (>37 U/ml), and number of metastatic lymph nodes (over three metastases). The multivariate analysis for recurrence identified three risk factors: rectal cancer, preoperative serum CEA level >5.0 ng/ml 95%, and more than three metastatic lymph nodes. Conclusion: The risk factors for stage III colorectal cancer recurrence seem to be rectal cancer, preoperative serum CEA level >5.0 ng/ml, and more than three metastatic lymph nodes.',\n",
       "   'Abstract Purpose Colon cancer is one of the malignant tumors that threatens human health. miR-510 was demonstrated to play roles in the progression of various cancers; its dysregulation was speculated to be associated with the development of colon cancer. Methods One hundred and thirteen colon cancer patients participated in this research. With the help of RT-qPCR, the expression of miR-510 in collected tissues and cultured cells was analyzed. The association between miR-510 expression level and clinical features and prognosis of patients was evaluated. Moreover, the effects of miR-510 on cell proliferation, migration, and invasion of colon cancer were assessed by CCK8 and Transwell assay. Results miR-510 significantly upregulated in colon cancer tissues and cell lines relative to the adjacent normal tissues and colonic cells. The expression of miR-510 was significantly associated with the TNM stage and poor prognosis of patients, indicating miR-510 was involved in the disease progression and clinical prognosis of colon cancer. Additionally, the upregulation of miR-510 significantly promoted cell proliferation, migration, and invasion of colon cancer, while its knockdown significantly inhibited these cellular processes. SRCIN 1 was the direct target of miR-510 during its promoted effect on the development of colon cancer. Conclusion The upregulation of miR-510 acts as an independent prognostic indicator and a tumor promoter by targeting SRCIN 1 in colon cancer, which provides novel therapeutic strategies for colon cancer.',\n",
       "   'Prostate cancer (PC) is a heterogeneous disease characterized by variable morphological patterns. Thus, establishing a patient-derived xenograft (PDX) model that retains the key features of the primary tumor for each type of PC is important for appropriate evaluation. In this study, we established PDX models of hormone-naïve (D17225) and castration-resistant (B45354) PC by implanting fresh tumor samples, obtained from patients with advanced PC under the renal capsule of immune-compromised mice. Supplementation with exogenous androgens shortened the latent period of tumorigenesis and increased the tumor formation rate. The PDX models exhibited the same major genomic and phenotypic features of the disease in humans and maintained the main pathological features of the primary tumors. Moreover, both PDX models showed different outcomes after castration or docetaxel treatment. The hormone-naïve D17225 PDX model displayed a range of responses from complete tumor regression to overt tumor progression, and the development of castrate-resistant PC was induced after castration. The responses of the two PDX models to androgen deprivation and docetaxel were similar to those observed in patients with advanced PC. These new preclinical PC models will facilitate research on the mechanisms underlying treatment response and resistance.',\n",
       "   'Patient: Female, 67 Final Diagnosis: Intrahepatic cholangiocarcinoma Symptoms: Atypical chest pain Medication: — Clinical Procedure: Liver biopsy Specialty: Internal Medicine/Oncology Objective: Rare disease Background: Intrahepatic cholangiocarcinoma is a rare condition which typically occurs in males between 50 and 70 years of age, and presents with symptoms related to biliary obstruction including jaundice, pruritus, and dark urine. Other common symptoms at presentation include abdominal pain, weight loss, and fever. Case Report: We present a case of a 67-year-old female initially presenting with chest pain at rest, found to have a lung nodule on diagnostic imaging at the time of admission. On further imaging, a 9 cm liver lesion was incidentally discovered, initially suspicious for hepatocellular carcinoma on imaging, with initial biopsy staining CK7 positive, and CK20 negative. The patient also had an elevated alpha-fetoprotein level. Biopsy results were later confirmed as moderately differentiated adenocarcinoma consistent with intrahepatic cholangiocarcinoma. Conclusions: This report illustrates an unusual presentation of intrahepatic cholangiocarcinoma. Although rare, cholangio-carcinoma is diagnosed most frequently as an incidental finding on imaging studies. With quick work-up and successful biopsy results, patients can undergo surgical or chemo-radiation therapy earlier, potentially leading to a longer survival time.',\n",
       "   'Purpose: Recent studies have suggested that osteopontin is induced by hypoxia in head and neck cancer cell lines and its plasma level may serve as a surrogate marker for tumor hypoxia and treatment outcome in head and neck cancer. We investigated the response of osteopontin to in vitro hypoxia in nasopharyngeal carcinoma cell lines, and determined plasma osteopontin levels in nasopharyngeal carcinoma patients, nonnasopharyngeal carcinoma head and neck cancer patients, and healthy controls. We explored the relationship of plasma osteopontin and response to radiotherapy in nasopharyngeal carcinoma. Experimental Design: Nasopharyngeal carcinoma cell lines HK1, HONE-1, C666-1, and CNE-2 were treated with 0 to 48 hours of hypoxia or normoxia, +/− reoxygenation. Osteopontin secretion in the supernatant was measured by ELISA assay. Cellular osteopontin protein and mRNA were detected by Western blotting and reverse transcription-PCR, respectively. Plasma osteopontin levels in patients (n = 66; 44 nasopharyngeal carcinoma, 22 head and neck cancer) and controls (n = 29) were measured by ELISA. Results: Hypoxia has no effect on osteopontin protein and mRNA level in nasopharyngeal carcinoma cells. Only CNE-2 secreted osteopontin, and there was no significant induction by hypoxia. Plasma osteopontin levels in patients of metastatic nasopharyngeal carcinoma and head and neck cancer, but not in locoregional nasopharyngeal carcinoma, were significantly higher than in controls. In patients with locoregional nasopharyngeal carcinoma receiving curative radiotherapy (n = 31), a high (>median) pretreatment plasma osteopontin level was a significant predictor of poor response to radiotherapy (complete response rate, 40% versus 88%; P = 0.009), which remained significant in multivariate analysis. Conclusion: Our results suggested that the pretreatment plasma osteopontin level may be a useful biomarker of response to radiotherapy in nasopharyngeal carcinoma.',\n",
       "   'Transarterial chemoembolization (TACE) is a therapeutic option for patients with intermediate‐stage hepatocellular carcinoma (HCC) or metastatic liver cancers. Identifying those patients who particularly benefit from TACE remains challenging. Macrophage migration inhibitory factor (MIF) represents is an inflammatory protein described in patients with liver cancer, but no data on its prognostic relevance in patients undergoing TACE exist. Here, we evaluate MIF serum concentrations as a potential biomarker in patients undergoing TACE for primary and secondary hepatic malignancies. MIF serum concentrations were measured by multiplex immunoassay in 50 patients (HCC: n = 39, liver metastases: n = 11) before and 1 day after TACE as well as in 51 healthy controls. Serum concentrations of MIF did not differ between patients and healthy controls. Interestingly, in the subgroup of patients with larger tumor size, significantly more patients had increased MIF concentrations. Patients with an objective tumor response to TACE therapy showed comparable concentrations of serum MIF compared to patients who did not respond. MIF concentrations at day 1 after TACE were significantly higher compared to baseline concentrations. Importantly, baseline MIF concentrations above the optimal cutoff value (0.625 ng/ml) turned out as a significant and independent prognostic marker for a reduced overall survival (OS) following TACE: patients with elevated MIF concentrations showed a significantly reduced median OS of only 719 days compared to patients below the cutoff value (median OS: 1430 days, p = 0.021). Baseline MIF serum concentrations are associated with tumor size of intrahepatic malignancies and predict outcome of patients with liver cancer receiving TACE.',\n",
       "   'Cancer vaccines are emerging as a viable strategy for cancer treatment. In the current study, we screened for genes associated with the prognosis of patients with lung adenocarcinoma and positively correlated with antigen-presenting cell infiltration and identified KLRG1 and CBFA2T3 as potential tumor antigens for mRNA vaccines in lung adenocarcinoma (LUAD). Further analyses of immune subtypes revealed that patients with early-stage LUAD, high immune cell infiltration, high immune checkpoint expression, and low tumor mutation burden might benefit from mRNA vaccination. Moreover, we identified four biomarkers that can be used to assess mRNA vaccination suitability. We also identified potentially sensitive anti-cancer drugs for populations not suitable for vaccination by means of anti-cancer drug susceptibility prediction. Overall, we provided a new perspective for mRNA vaccine treatment strategies for LUAD and emphasized the importance of precise and personalized treatments.',\n",
       "   'Background: Recurrent laryngeal nerve paralysis (RLNP), a severe complication of mini-invasive esophagectomy, usually occurs during lymphadenectomy adjacent to recurrent laryngeal nerve. This systematic review and meta-analysis aimed to evaluate the efficacy of intraoperative nerve monitoring (IONM) in reducing RLNP incidence during mini-invasive esophagectomy. Methods: Systematic literature search of PubMed, EMBASE, EBSCO, Web of Knowledge, and Cochrane Library until June 4, 2021 was performed using the terms “(nerve monitoring) OR neuromonitoring OR neural monitoring OR recurrent laryngeal nerve AND (esophagectomy OR esophageal).” Primary outcome was postoperative RLNP incidence. Secondary outcomes were sensitivity, specificity, and positive and negative predictive values for IONM; complications after esophagectomy; number of dissected lymph nodes; operation time; and length of hospital stay. Results: Among 2,330 studies, five studies comprising 509 patients were eligible for final analysis. The RLNP incidence was significantly lower (odds ratio [OR] 0.33, 95% confidence interval [CI] 0.12–0.88, p < 0.05), the number of dissected mediastinal lymph nodes was significantly higher (mean difference 4.30, 95%CI 2.75–5.85, p < 0.001), and the rate of hoarseness was significantly lower (OR 0.14, 95%CI 0.03–0.63, p = 0.01) in the IONM group than in the non-IONM group. The rates of aspiration (OR 0.31, 95%CI 0.06–1.64, p = 0.17), pneumonia (OR 1.08, 95%CI 0.70–1.67, p = 0.71), and operation time (mean difference 7.68, 95%CI −23.60–38.95, p = 0.63) were not significantly different between the two groups. The mean sensitivity, specificity, and positive and negative predictive values for IONM were 53.2% (0–66.7%), 93.7% (54.8–100%), 71.4% (0–100%), and 87.1% (68.0–96.6%), respectively. Conclusion: IONM was a feasible and effective approach to minimize RLNP, improve lymphadenectomy, and reduce hoarseness after thoracoscopic esophagectomy for esophageal cancer, although IONM did not provide significant benefit in reducing aspiration, pneumonia, operation time, and length of hospital stay.',\n",
       "   'Aim: The Italian Piedmont region sponsored in 2005 a population‐based registry to assess the epidemiology of childhood chronic organ failure involving kidneys, liver, heart or lungs.']]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embeddings = get_question_embeddings(question)\n",
    "results = query_chroma(question_embeddings)\n",
    "\n",
    "for k in results.keys(): \n",
    "    try: \n",
    "        results[k] = results[k][0]\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LED model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, LongformerForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "led_tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\")\n",
    "led_model = LongformerForQuestionAnswering.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''.join(results['documents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = led_tokenizer(question, text, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = encoding[\"input_ids\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default is local attention everywhere\n",
    "# the forward method will automatically set global attention on question tokens\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "\n",
    "outputs = led_model(input_ids, attention_mask=attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "all_tokens = led_tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "\n",
    "answer_tokens = all_tokens[torch.argmax(start_logits) : torch.argmax(end_logits) + 1]\n",
    "\n",
    "answer = led_tokenizer.decode(\n",
    "    led_tokenizer.convert_tokens_to_ids(answer_tokens)\n",
    ")  # remove space prepending space token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Microvascular density (MVD), a marker for tumor angiogenesis, has been demonstrated to have prognostic significance in various malignancies. Previous studies have demonstrated that MVD is an independent prognostic factor in pancreatic adenocarcinoma and that longer survival is associated with hypovascular tumors. The prognostic importance of MVD in pancreatic neuroendocrine tumor (NET) has not been documented. We evaluated MVD in pancreatic NET and correlated it with clinicopathologic features and patient outcome to determine whether MVD is a useful prognostic indicator for these patients. Twenty-five pancreatic NETs from our archival files resected between 1981 and 2000 were identified. The mean MVD was determined for each tumor from the 3 most vascularized 200 × fields. Clinical follow-up ranged from 1 to 19 years, with a mean of 4.9 years. At last follow-up, 6 patients were dead of disease, 10 patients were alive without disease, 4 patients were alive with disease, and 5 patients were alive with disease status unknown. Mean MVD ranged from 43 to 527 microvessels per 200 × field. MVD did not correlate with tumor size, the examined histologic parameters, or patient outcome. MVD in pancreatic NET does not correlate with the clinicohistologic features', metadata={}),\n",
       " Document(page_content='with the clinicohistologic features evaluated in this study or with the patient outcome and is not a useful prognostic indicator in these patients. These results suggest that factors other than the simple number of microvessels are important in determining pancreatic NET behavior. However, most tumors were highly vascular, and additional studies may be helpful to clarify further the role of vascularity and assess the utility of antiangiogenic agents in the treatment of pancreatic NET.', metadata={}),\n",
       " Document(page_content='Background/Aim: This study aimed to identify risk factors for recurrence of patients with stage III colorectal cancer by assessing clinicopathological features. Patients and Methods: The study included 231 patients with stage III colorectal cancer who underwent curative resection between 2006 and 2012 at the Department of Surgery of the Jikei University Hospital, Tokyo, Japan. Clinicopathological data of the patients were retrospectively evaluated. Results: The recurrence rate was 27.7% (64/231) in the study group. The univariate analysis for recurrence identified five risk factors: site of primary tumor (rectal cancer), surgical procedure (open surgery), preoperative serum CEA level (>5 ng/ml), preoperative serum CA19-9 level (>37 U/ml), and number of metastatic lymph nodes (over three metastases). The multivariate analysis for recurrence identified three risk factors: rectal cancer, preoperative serum CEA level >5.0 ng/ml 95%, and more than three metastatic lymph nodes. Conclusion: The risk factors for stage III colorectal cancer recurrence seem to be rectal cancer, preoperative serum CEA level >5.0 ng/ml, and more than three metastatic lymph nodes.', metadata={}),\n",
       " Document(page_content='Abstract Purpose Colon cancer is one of the malignant tumors that threatens human health. miR-510 was demonstrated to play roles in the progression of various cancers; its dysregulation was speculated to be associated with the development of colon cancer. Methods One hundred and thirteen colon cancer patients participated in this research. With the help of RT-qPCR, the expression of miR-510 in collected tissues and cultured cells was analyzed. The association between miR-510 expression level and clinical features and prognosis of patients was evaluated. Moreover, the effects of miR-510 on cell proliferation, migration, and invasion of colon cancer were assessed by CCK8 and Transwell assay. Results miR-510 significantly upregulated in colon cancer tissues and cell lines relative to the adjacent normal tissues and colonic cells. The expression of miR-510 was significantly associated with the TNM stage and poor prognosis of patients, indicating miR-510 was involved in the disease progression and clinical prognosis of colon cancer. Additionally, the upregulation of miR-510 significantly promoted cell proliferation, migration, and invasion of colon cancer, while its knockdown significantly inhibited these cellular processes. SRCIN 1 was the direct target of miR-510 during its promoted effect on the development of colon cancer.', metadata={}),\n",
       " Document(page_content='development of colon cancer. Conclusion The upregulation of miR-510 acts as an independent prognostic indicator and a tumor promoter by targeting SRCIN 1 in colon cancer, which provides novel therapeutic strategies for colon cancer.', metadata={}),\n",
       " Document(page_content='Prostate cancer (PC) is a heterogeneous disease characterized by variable morphological patterns. Thus, establishing a patient-derived xenograft (PDX) model that retains the key features of the primary tumor for each type of PC is important for appropriate evaluation. In this study, we established PDX models of hormone-naïve (D17225) and castration-resistant (B45354) PC by implanting fresh tumor samples, obtained from patients with advanced PC under the renal capsule of immune-compromised mice. Supplementation with exogenous androgens shortened the latent period of tumorigenesis and increased the tumor formation rate. The PDX models exhibited the same major genomic and phenotypic features of the disease in humans and maintained the main pathological features of the primary tumors. Moreover, both PDX models showed different outcomes after castration or docetaxel treatment. The hormone-naïve D17225 PDX model displayed a range of responses from complete tumor regression to overt tumor progression, and the development of castrate-resistant PC was induced after castration. The responses of the two PDX models to androgen deprivation and docetaxel were similar to those observed in patients with advanced PC. These new preclinical PC models will facilitate research on the mechanisms underlying treatment response and resistance.', metadata={}),\n",
       " Document(page_content='Patient: Female, 67 Final Diagnosis: Intrahepatic cholangiocarcinoma Symptoms: Atypical chest pain Medication: — Clinical Procedure: Liver biopsy Specialty: Internal Medicine/Oncology Objective: Rare disease Background: Intrahepatic cholangiocarcinoma is a rare condition which typically occurs in males between 50 and 70 years of age, and presents with symptoms related to biliary obstruction including jaundice, pruritus, and dark urine. Other common symptoms at presentation include abdominal pain, weight loss, and fever. Case Report: We present a case of a 67-year-old female initially presenting with chest pain at rest, found to have a lung nodule on diagnostic imaging at the time of admission. On further imaging, a 9 cm liver lesion was incidentally discovered, initially suspicious for hepatocellular carcinoma on imaging, with initial biopsy staining CK7 positive, and CK20 negative. The patient also had an elevated alpha-fetoprotein level. Biopsy results were later confirmed as moderately differentiated adenocarcinoma consistent with intrahepatic cholangiocarcinoma. Conclusions: This report illustrates an unusual presentation of intrahepatic cholangiocarcinoma. Although rare, cholangio-carcinoma is diagnosed most frequently as an incidental finding on imaging studies. With quick work-up and successful biopsy results, patients can undergo surgical or chemo-radiation therapy earlier, potentially leading to a longer', metadata={}),\n",
       " Document(page_content='leading to a longer survival time.', metadata={}),\n",
       " Document(page_content='Purpose: Recent studies have suggested that osteopontin is induced by hypoxia in head and neck cancer cell lines and its plasma level may serve as a surrogate marker for tumor hypoxia and treatment outcome in head and neck cancer. We investigated the response of osteopontin to in vitro hypoxia in nasopharyngeal carcinoma cell lines, and determined plasma osteopontin levels in nasopharyngeal carcinoma patients, nonnasopharyngeal carcinoma head and neck cancer patients, and healthy controls. We explored the relationship of plasma osteopontin and response to radiotherapy in nasopharyngeal carcinoma. Experimental Design: Nasopharyngeal carcinoma cell lines HK1, HONE-1, C666-1, and CNE-2 were treated with 0 to 48 hours of hypoxia or normoxia, +/− reoxygenation. Osteopontin secretion in the supernatant was measured by ELISA assay. Cellular osteopontin protein and mRNA were detected by Western blotting and reverse transcription-PCR, respectively. Plasma osteopontin levels in patients (n = 66; 44 nasopharyngeal carcinoma, 22 head and neck cancer) and controls (n = 29) were measured by ELISA. Results: Hypoxia has no effect on osteopontin protein and mRNA level in nasopharyngeal carcinoma cells. Only CNE-2 secreted osteopontin, and there was no significant induction by hypoxia.', metadata={}),\n",
       " Document(page_content='significant induction by hypoxia. Plasma osteopontin levels in patients of metastatic nasopharyngeal carcinoma and head and neck cancer, but not in locoregional nasopharyngeal carcinoma, were significantly higher than in controls. In patients with locoregional nasopharyngeal carcinoma receiving curative radiotherapy (n = 31), a high (>median) pretreatment plasma osteopontin level was a significant predictor of poor response to radiotherapy (complete response rate, 40% versus 88%; P = 0.009), which remained significant in multivariate analysis. Conclusion: Our results suggested that the pretreatment plasma osteopontin level may be a useful biomarker of response to radiotherapy in nasopharyngeal carcinoma.', metadata={}),\n",
       " Document(page_content='Transarterial chemoembolization (TACE) is a therapeutic option for patients with intermediate‐stage hepatocellular carcinoma (HCC) or metastatic liver cancers. Identifying those patients who particularly benefit from TACE remains challenging. Macrophage migration inhibitory factor (MIF) represents is an inflammatory protein described in patients with liver cancer, but no data on its prognostic relevance in patients undergoing TACE exist. Here, we evaluate MIF serum concentrations as a potential biomarker in patients undergoing TACE for primary and secondary hepatic malignancies. MIF serum concentrations were measured by multiplex immunoassay in 50 patients (HCC: n = 39, liver metastases: n = 11) before and 1 day after TACE as well as in 51 healthy controls. Serum concentrations of MIF did not differ between patients and healthy controls. Interestingly, in the subgroup of patients with larger tumor size, significantly more patients had increased MIF concentrations. Patients with an objective tumor response to TACE therapy showed comparable concentrations of serum MIF compared to patients who did not respond. MIF concentrations at day 1 after TACE were significantly higher compared to baseline concentrations. Importantly, baseline MIF concentrations above the optimal cutoff value (0.625 ng/ml) turned out as a significant and independent prognostic', metadata={}),\n",
       " Document(page_content='significant and independent prognostic marker for a reduced overall survival (OS) following TACE: patients with elevated MIF concentrations showed a significantly reduced median OS of only 719 days compared to patients below the cutoff value (median OS: 1430 days, p = 0.021). Baseline MIF serum concentrations are associated with tumor size of intrahepatic malignancies and predict outcome of patients with liver cancer receiving TACE.', metadata={}),\n",
       " Document(page_content='Cancer vaccines are emerging as a viable strategy for cancer treatment. In the current study, we screened for genes associated with the prognosis of patients with lung adenocarcinoma and positively correlated with antigen-presenting cell infiltration and identified KLRG1 and CBFA2T3 as potential tumor antigens for mRNA vaccines in lung adenocarcinoma (LUAD). Further analyses of immune subtypes revealed that patients with early-stage LUAD, high immune cell infiltration, high immune checkpoint expression, and low tumor mutation burden might benefit from mRNA vaccination. Moreover, we identified four biomarkers that can be used to assess mRNA vaccination suitability. We also identified potentially sensitive anti-cancer drugs for populations not suitable for vaccination by means of anti-cancer drug susceptibility prediction. Overall, we provided a new perspective for mRNA vaccine treatment strategies for LUAD and emphasized the importance of precise and personalized treatments.', metadata={}),\n",
       " Document(page_content='Background: Recurrent laryngeal nerve paralysis (RLNP), a severe complication of mini-invasive esophagectomy, usually occurs during lymphadenectomy adjacent to recurrent laryngeal nerve. This systematic review and meta-analysis aimed to evaluate the efficacy of intraoperative nerve monitoring (IONM) in reducing RLNP incidence during mini-invasive esophagectomy. Methods: Systematic literature search of PubMed, EMBASE, EBSCO, Web of Knowledge, and Cochrane Library until June 4, 2021 was performed using the terms “(nerve monitoring) OR neuromonitoring OR neural monitoring OR recurrent laryngeal nerve AND (esophagectomy OR esophageal).” Primary outcome was postoperative RLNP incidence. Secondary outcomes were sensitivity, specificity, and positive and negative predictive values for IONM; complications after esophagectomy; number of dissected lymph nodes; operation time; and length of hospital stay. Results: Among 2,330 studies, five studies comprising 509 patients were eligible for final analysis. The RLNP incidence was significantly lower (odds ratio [OR] 0.33, 95% confidence interval [CI] 0.12–0.88, p < 0.05), the number of dissected mediastinal lymph nodes was significantly higher (mean difference 4.30, 95%CI 2.75–5.85, p < 0.001), and the rate of hoarseness was significantly lower (OR 0.14, 95%CI 0.03–0.63, p = 0.01)', metadata={}),\n",
       " Document(page_content='p = 0.01) in the IONM group than in the non-IONM group. The rates of aspiration (OR 0.31, 95%CI 0.06–1.64, p = 0.17), pneumonia (OR 1.08, 95%CI 0.70–1.67, p = 0.71), and operation time (mean difference 7.68, 95%CI −23.60–38.95, p = 0.63) were not significantly different between the two groups. The mean sensitivity, specificity, and positive and negative predictive values for IONM were 53.2% (0–66.7%), 93.7% (54.8–100%), 71.4% (0–100%), and 87.1% (68.0–96.6%), respectively. Conclusion: IONM was a feasible and effective approach to minimize RLNP, improve lymphadenectomy, and reduce hoarseness after thoracoscopic esophagectomy for esophageal cancer, although IONM did not provide significant benefit in reducing aspiration, pneumonia, operation time, and length of hospital stay.', metadata={}),\n",
       " Document(page_content='Aim: The Italian Piedmont region sponsored in 2005 a population‐based registry to assess the epidemiology of childhood chronic organ failure involving kidneys, liver, heart or lungs.', metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = text_splitter.create_documents(results['documents'][0])\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class specter_ef(EmbeddingFunction):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def embed_documents(self, texts: Documents) -> Embeddings:\n",
    "        \n",
    "        text_list = [re.sub(\"\\n\", \" \", p) for p in texts]\n",
    "        texts = [re.sub(\"\\s\\s+\", \" \", t) for t in text_list]\n",
    "        \n",
    "        # embed the documents somehow\n",
    "        embeddings = []\n",
    "        \n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "            result = model(**inputs)\n",
    "            embeddings.append(result.last_hidden_state[:, 0, :])\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "specter_embeder = specter_ef(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words and punctuation from a string using the nltk library\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = 'Background: Recurrent laryngeal nerve paralysis (RLNP), a severe complication of mini-invasive esophagectomy, usually occurs during lymphadenectomy adjacent to recurrent laryngeal nerve. '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove stop words from test_string\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "exclude_punctuation = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine stop words and punctuation marks\n",
    "exclude = set.union(stop_words, exclude_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stop_words to remove stop words from test_string\n",
    "test_string = ' '.join([word for word in test_string.split() if word not in exclude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings import LangchainEmbedding\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up ChromaVectorStore and load in data\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "\n",
    "for d in range(len(results['documents'])): \n",
    "    nodes.append(TextNode(\n",
    "        text = results['documents'][d],\n",
    "        metadata = results['metadatas'][d]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StorageContext.from_defaults() got an unexpected keyword argument 'llm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vector_store \u001b[39m=\u001b[39m ChromaVectorStore(chroma_collection\u001b[39m=\u001b[39mcollection)\n\u001b[0;32m----> 2\u001b[0m storage_context \u001b[39m=\u001b[39m StorageContext\u001b[39m.\u001b[39;49mfrom_defaults(vector_store\u001b[39m=\u001b[39;49mvector_store, llm \u001b[39m=\u001b[39;49m led_model)\n",
      "\u001b[0;31mTypeError\u001b[0m: StorageContext.from_defaults() got an unexpected keyword argument 'llm'"
     ]
    }
   ],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x7f6e6dbae260 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/embeddings/openai.py:150\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(list_of_text, engine, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m list_of_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n\u001b[0;32m--> 150\u001b[0m data \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mlist_of_text, model\u001b[39m=\u001b[39;49mengine, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mdata\n\u001b[1;32m    151\u001b[0m \u001b[39mreturn\u001b[39;00m [d[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[1;32m    141\u001b[0m         timeout,\n\u001b[1;32m    142\u001b[0m         stream,\n\u001b[1;32m    143\u001b[0m         headers,\n\u001b[1;32m    144\u001b[0m         request_timeout,\n\u001b[1;32m    145\u001b[0m         typed_api_type,\n\u001b[1;32m    146\u001b[0m         requestor,\n\u001b[1;32m    147\u001b[0m         url,\n\u001b[1;32m    148\u001b[0m         params,\n\u001b[0;32m--> 149\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__prepare_create_request(\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[1;32m    153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    104\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 106\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[1;32m    107\u001b[0m     api_key,\n\u001b[1;32m    108\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[1;32m    109\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[1;32m    110\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    111\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    113\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/openai/api_requestor.py:138\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[0;32m--> 138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[1;32m    140\u001b[0m     ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m api_type\n\u001b[1;32m    142\u001b[0m     \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[1;32m    143\u001b[0m )\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index \u001b[39m=\u001b[39m VectorStoreIndex(nodes, storage_context\u001b[39m=\u001b[39;49mstorage_context)\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:46\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[0;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_async \u001b[39m=\u001b[39m use_async\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override \u001b[39m=\u001b[39m store_nodes_override\n\u001b[0;32m---> 46\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     47\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[1;32m     48\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[1;32m     49\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[1;32m     50\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[1;32m     51\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m     52\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/indices/base.py:71\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39massert\u001b[39;00m nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(nodes)\n\u001b[1;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n\u001b[1;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage_context\u001b[39m.\u001b[39mindex_store\u001b[39m.\u001b[39madd_index_struct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct)\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:241\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_index_from_nodes\u001b[39m(\u001b[39mself\u001b[39m, nodes: Sequence[BaseNode]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m IndexDict:\n\u001b[1;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build the index from nodes.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[39m    NOTE: Overrides BaseIndex.build_index_from_nodes.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m        VectorStoreIndex only stores nodes in document store\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m        if vector store does not store text\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_nodes(nodes)\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:229\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    227\u001b[0m     run_async_tasks(tasks)\n\u001b[1;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_nodes_to_index(\n\u001b[1;32m    230\u001b[0m         index_struct, nodes, show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress\n\u001b[1;32m    231\u001b[0m     )\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:201\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[0;34m(self, index_struct, nodes, show_progress)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nodes:\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m embedding_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_embedding_results(nodes, show_progress)\n\u001b[1;32m    202\u001b[0m new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39madd(embedding_results)\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mstores_text \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override:\n\u001b[1;32m    205\u001b[0m     \u001b[39m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[39m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:111\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_embedding_results\u001b[0;34m(self, nodes, show_progress)\u001b[0m\n\u001b[1;32m    105\u001b[0m         id_to_embed_map[n\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m n\u001b[39m.\u001b[39membedding\n\u001b[1;32m    107\u001b[0m \u001b[39m# call embedding model to get embeddings\u001b[39;00m\n\u001b[1;32m    108\u001b[0m (\n\u001b[1;32m    109\u001b[0m     result_ids,\n\u001b[1;32m    110\u001b[0m     result_embeddings,\n\u001b[0;32m--> 111\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service_context\u001b[39m.\u001b[39;49membed_model\u001b[39m.\u001b[39;49mget_queued_text_embeddings(show_progress)\n\u001b[1;32m    112\u001b[0m \u001b[39mfor\u001b[39;00m new_id, text_embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result_ids, result_embeddings):\n\u001b[1;32m    113\u001b[0m     id_to_embed_map[new_id] \u001b[39m=\u001b[39m text_embedding\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/embeddings/base.py:180\u001b[0m, in \u001b[0;36mBaseEmbedding.get_queued_text_embeddings\u001b[0;34m(self, show_progress)\u001b[0m\n\u001b[1;32m    178\u001b[0m cur_batch_ids \u001b[39m=\u001b[39m [text_id \u001b[39mfor\u001b[39;00m text_id, _ \u001b[39min\u001b[39;00m cur_batch]\n\u001b[1;32m    179\u001b[0m cur_batch_texts \u001b[39m=\u001b[39m [text \u001b[39mfor\u001b[39;00m _, text \u001b[39min\u001b[39;00m cur_batch]\n\u001b[0;32m--> 180\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_embeddings(cur_batch_texts)\n\u001b[1;32m    181\u001b[0m result_ids\u001b[39m.\u001b[39mextend(cur_batch_ids)\n\u001b[1;32m    182\u001b[0m result_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/embeddings/openai.py:267\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_text_embeddings\u001b[39m(\u001b[39mself\u001b[39m, texts: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[\u001b[39mfloat\u001b[39m]]:\n\u001b[1;32m    261\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get text embeddings.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \n\u001b[1;32m    263\u001b[0m \u001b[39m    By default, this is a wrapper around _get_text_embedding.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    Can be overriden for batch queries.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \n\u001b[1;32m    266\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mreturn\u001b[39;00m get_embeddings(\n\u001b[1;32m    268\u001b[0m         texts,\n\u001b[1;32m    269\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext_engine,\n\u001b[1;32m    270\u001b[0m         deployment_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment_name,\n\u001b[1;32m    271\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopenai_kwargs,\n\u001b[1;32m    272\u001b[0m     )\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7f6e6dbae260 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'led_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m service_context \u001b[39m=\u001b[39m ServiceContext\u001b[39m.\u001b[39mfrom_defaults(llm \u001b[39m=\u001b[39m led_model, chunk_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'led_model' is not defined"
     ]
    }
   ],
   "source": [
    "# service_context = ServiceContext.from_defaults(llm = led_model, chunk_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'get_doc_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index \u001b[39m=\u001b[39m VectorStoreIndex\u001b[39m.\u001b[39;49mfrom_documents(\n\u001b[1;32m      2\u001b[0m     documents,\n\u001b[1;32m      3\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[1;32m      4\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/indices/base.py:97\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[0;34m(cls, documents, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mwith\u001b[39;00m service_context\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mas_trace(\u001b[39m\"\u001b[39m\u001b[39mindex_construction\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     96\u001b[0m     \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents:\n\u001b[0;32m---> 97\u001b[0m         docstore\u001b[39m.\u001b[39mset_document_hash(doc\u001b[39m.\u001b[39;49mget_doc_id(), doc\u001b[39m.\u001b[39mhash)\n\u001b[1;32m     98\u001b[0m     nodes \u001b[39m=\u001b[39m service_context\u001b[39m.\u001b[39mnode_parser\u001b[39m.\u001b[39mget_nodes_from_documents(\n\u001b[1;32m     99\u001b[0m         documents, show_progress\u001b[39m=\u001b[39mshow_progress\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\n\u001b[1;32m    103\u001b[0m         nodes\u001b[39m=\u001b[39mnodes,\n\u001b[1;32m    104\u001b[0m         storage_context\u001b[39m=\u001b[39mstorage_context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    108\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'get_doc_id'"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Query Data\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "ChromaReader = download_loader(\"ChromaReader\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ChromaReader:\n",
      "\n",
      "class ChromaReader(llama_index.readers.base.BaseReader)\n",
      " |  ChromaReader(collection_name: str, persist_directory: str) -> None\n",
      " |  \n",
      " |  Chroma reader.\n",
      " |  \n",
      " |  Retrieve documents from existing persisted Chroma collections.\n",
      " |  \n",
      " |  Args:\n",
      " |      collection_name: Name of the peristed collection.\n",
      " |      persist_directory: Directory where the collection is persisted.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ChromaReader\n",
      " |      llama_index.readers.base.BaseReader\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, collection_name: str, persist_directory: str) -> None\n",
      " |      Initialize with parameters.\n",
      " |  \n",
      " |  load_data(self, query_vector: Any, limit: int = 10) -> Any\n",
      " |      Load data from Chroma.\n",
      " |      \n",
      " |      Args:\n",
      " |          query_vector (Any): Query\n",
      " |          limit (int): Number of results to return.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Document]: A list of documents.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from llama_index.readers.base.BaseReader:\n",
      " |  \n",
      " |  load_langchain_documents(self, **load_kwargs: Any) -> List[langchain.schema.document.Document]\n",
      " |      Load data in LangChain document format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from llama_index.readers.base.BaseReader:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ChromaReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chromadb.api.fastapi.FastAPI at 0x7f6e7113a170>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for Settings\npersist_directory\n  str type expected (type=type_error.str)\nis_persistent\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# The chroma reader loads data from a persisted Chroma collection.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# This requires a collection name and a persist directory.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m reader \u001b[39m=\u001b[39m ChromaReader(\n\u001b[1;32m      4\u001b[0m     collection_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mspecter_abstracts\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mcollection\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/chroma/base.py:33\u001b[0m, in \u001b[0;36mChromaReader.__init__\u001b[0;34m(self, collection_name, persist_directory)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mif\u001b[39;00m (collection_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m (persist_directory \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     30\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease provide a collection name and persist directory.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client \u001b[39m=\u001b[39m chromadb\u001b[39m.\u001b[39mClient(\n\u001b[0;32m---> 33\u001b[0m     Settings(\n\u001b[1;32m     34\u001b[0m         is_persistent\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, persist_directory\u001b[39m=\u001b[39;49mpersist_directory\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mget_collection(collection_name)\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/pydantic/env_settings.py:40\u001b[0m, in \u001b[0;36mpydantic.env_settings.BaseSettings.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/work/therapeutic_accelerator/.venv/lib/python3.10/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for Settings\npersist_directory\n  str type expected (type=type_error.str)\nis_persistent\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "# The chroma reader loads data from a persisted Chroma collection.\n",
    "# This requires a collection name and a persist directory.\n",
    "reader = ChromaReader(\n",
    "    collection_name=\"specter_abstracts\",\n",
    "    persist_directory=collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_vector=[n1, n2, n3, ...]\n",
    "\n",
    "documents = reader.load_data(collection_name=\"demo\", query_vector=query_vector, limit=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
