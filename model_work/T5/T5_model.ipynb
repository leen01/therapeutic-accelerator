{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile as zf\n",
    "from glob import glob\n",
    "\n",
    "# from keras.saving.hdf5_format import save_attributes_to_hdf5_group\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    TFT5Model,\n",
    "    TFT5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    TFBertModel,\n",
    "    AutoModel,\n",
    "    TFBertForQuestionAnswering,\n",
    ")\n",
    "import sentencepiece\n",
    "from metapub import PubMedFetcher\n",
    "from semanticscholar import SemanticScholar\n",
    "from metapub import FindIt\n",
    "import requests\n",
    "import urllib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from a file stored in a different directory\n",
    "import sys\n",
    "sys.path.append('~/work/therapeutic_accelerator/scripts/utils')\n",
    "sys.path.append('~/work/therapeutic_accelerator/scripts/database')\n",
    "\n",
    "from utils import import_config\n",
    "from db_tools import db_connection\n",
    "\n",
    "config, keys = import_config()\n",
    "\n",
    "engine = db_connection(password = keys[\"postgres\"], host = config[\"database\"][\"host\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard coded variables\n",
    "max_sequence_length = 512\n",
    "embedding_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T5Abstract_model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "T5tokens = T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### T5 Abstractive Text Summarization Model\n",
    "def t5summary_model(tokenizer, text, t5model):\n",
    "    summarize = \"summarize: \"\n",
    "    encoding = tokenizer([summarize+text], return_tensors='tf')\n",
    "    output = t5model.generate(encoding.input_ids,\n",
    "                             num_beams=3,\n",
    "                            no_repeat_ngram_size=2,\n",
    "                              top_k=10,\n",
    "                              top_p=80,\n",
    "                              max_length=50,\n",
    "                              min_length=30\n",
    "                             )\n",
    "    return [tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in output]\n",
    "#     print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5summary_model(T5tokens, text_example, T5Abstract_model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
