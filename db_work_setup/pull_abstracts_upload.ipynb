{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(\"/home/ubuntu/work/therapeutic_accelerator/config/main.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "with open(\"../config/keys.yaml\", \"r\") as f:\n",
    "    keys = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "bucket_path = os.path.join(config['paths']['root'], config['paths']['mount'])\n",
    "\n",
    "from typing import TypeVar\n",
    "T = TypeVar('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the sql database connection\n",
    "# 'postgresql://<username>:<password@<host>:<port>/postgres'\n",
    "engine = create_engine(f'postgresql://postgres:{keys[\"postgres\"]}@{config[\"database\"][\"host\"]}:5432/postgres')\n",
    "\n",
    "# Query to pull in corpus IDs\n",
    "\n",
    "sql = '''\n",
    "    SELECT * FROM attributes LEFT JOIN abstracts ON corpusId;\n",
    "'''\n",
    "\n",
    "# Context manager to open the connection to the database and execute the query. \n",
    "with engine.connect() as conn:\n",
    "    query = conn.execute(text(sql))\n",
    "    \n",
    "# Get all records and store in dataframe\n",
    "df = pd.DataFrame(query.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "\n",
    "# Create connection to Semantic Scholar\n",
    "sch = SemanticScholar(api_key=keys['semantic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(items: list[T], batch_size: int) -> list[T]:\n",
    "    \"\"\"Create batched list for api calls broken into \n",
    "\n",
    "    Args:\n",
    "        items (list[T]): _description_\n",
    "        batch_size (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        list[T]: Batched list \n",
    "    \"\"\"\n",
    "    return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch:   0%|          | 0/1460 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 1460/1460 [32:03<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Takes about 30 minutes to run all 700K ids\n",
    "with open('papers_abstracts.csv', 'w') as csvfile:\n",
    "    fieldnames = ['paperId', 'corpusId', 'abstract']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # ids = [f'PMID:{pmid}' for pmid in pmids]\n",
    "    # fields = 'corpusId,abstract,pmid'\n",
    "    batch_size = 500\n",
    "    \n",
    "    # The `tqdm` wrapper should display a progress bar for the loop\n",
    "    for ids_batch in tqdm(batched(ids, batch_size=batch_size), desc = 'batch'):\n",
    "        # Get the papers based off UUID in batches, convert to dataframe for DB uploading\n",
    "        results = pd.DataFrame([dict(i) for i in sch.get_papers(ids_batch, fields=fieldnames)])\n",
    "        \n",
    "        # set corpus id as the index for quicker lookup times\n",
    "        results = results.set_index('corpusId')\n",
    "\n",
    "        # Create `abstracts` table within our postgres DB. Watch for replace if we are updating the data table\n",
    "        with engine.connect() as conn:\n",
    "            results.to_sql('abstracts', con=conn, if_exists='append', index=True, chunksize = 500)\n",
    "        \n",
    "        # appends results to csv file. Save as backup incase DB does not work properly\n",
    "        results.to_csv(csvfile, mode ='a', header=False)\n",
    "\n",
    "        # sleep to avoid hiting request limits of 5000 requests per five minutes\n",
    "        # time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test that it uploaded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure DB creation worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729817, 4)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    SELECT * FROM abstracts;\n",
    "'''\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    query = conn.execute(text(sql))   \n",
    "          \n",
    "df = pd.DataFrame(query.fetchall())\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup abstracts DB as CSV\n",
    "df.to_csv(\"/home/ubuntu/work/therapeutic_accelerator/db_work/papers_abstracts_backup.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check connection between attributes and abstracts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
