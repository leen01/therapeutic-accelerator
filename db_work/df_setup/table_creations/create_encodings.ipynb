{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "# import dask\n",
    "\n",
    "# set up\n",
    "with open(\"/home/ubuntu/work/therapeutic_accelerator/config/main.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "with open(\"../config/keys.yaml\", \"r\") as f:\n",
    "    keys = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "url_object = URL.create(\n",
    "    'postgresql', \n",
    "    username='postgres',\n",
    "    password=keys[\"postgres\"], \n",
    "    host=config[\"database\"][\"host\"],\n",
    "    database='postgres',\n",
    "    port=5432\n",
    ")\n",
    "\n",
    "# Create engine to connect to database\n",
    "# psql_string = f'postgresql://postgres:{keys[\"postgres\"]}@{config[\"database\"][\"host\"]}:5432/postgres'\n",
    "engine = create_engine(url_object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch\n",
    "max_sequence_length = 1200\n",
    "embedding_size = 200\n",
    "\n",
    "from transformers import T5Tokenizer # AutoModel, AutoTokenizer, BertTokenizer,BioGptModel, BioGptConfig, BioGptTokenizer\n",
    "T5tokens = T5Tokenizer.from_pretrained('t5-base', model_max_length = max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio_bert_model = AutoModel.from_pretrained(\"gsarti/biobert-nli\")\n",
    "# bio_bert_tokenizer = AutoTokenizer.from_pretrained(\"gsarti/biobert-nli\")\n",
    "# original_bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# T5Abstract_model = TFT5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "# biogpttokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "# biogptmodel = BioGptModel.from_pretrained(\"microsoft/biogpt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot Test: Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pull all the abstracts\n",
    "# sql = '''SELECT * FROM abstracts LIMIT 5'''\n",
    "# with engine.connect() as conn: \n",
    "#     results = conn.execute(text(sql))\n",
    "\n",
    "# # Turn into dataframe    \n",
    "# abstracts = pd.DataFrame(results.fetchall())\n",
    "\n",
    "# # Remove empty abstracts\n",
    "# print(\"Shape before: \", abstracts.shape)\n",
    "# abstracts = abstracts.dropna(how = 'all', subset='abstract').reset_index(drop = True)\n",
    "# print(\"Shape after: \", abstracts.shape)\n",
    "\n",
    "# # Distribution of abstract lengths\n",
    "# ab_lens = abstracts.abstract.apply(lambda x: len(x.split()))\n",
    "\n",
    "# # Lengths of Abstracts\n",
    "# display(ab_lens.describe())\n",
    "\n",
    "# from seaborn import displot\n",
    "# displot(ab_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create new columns for DB table\n",
    "# abstracts[['input_ids', 'attention_mask']] = abstracts.abstract.apply(T5tokens).apply(pd.Series)\n",
    "\n",
    "# # Cleanup\n",
    "# abstracts.drop(['index', 'id'], axis = 1, inplace = True)\n",
    "\n",
    "# # QA check\n",
    "# abstracts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Encodings using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_sql_table('abstracts', \n",
    "                        con = f'postgresql://postgres:{keys[\"postgres\"]}@{config[\"database\"][\"host\"]}:5432/postgres',\n",
    "                        index_col = 'id',\n",
    "                        head_rows = 5,\n",
    "                        npartitions = 200)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "ddf = ddf.drop(columns = ['index'])\n",
    "\n",
    "# Remove empty abstract rows\n",
    "ddf = ddf.dropna(how = 'all', subset='abstract').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.10/site-packages/dask/dataframe/multi.py:1291: UserWarning: Concatenating dataframes with unknown divisions.\n",
      "We're assuming that the indices of each dataframes are \n",
      " aligned. This assumption is not generally safe.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create new columns for DB table\n",
    "ddf2 = ddf.abstract.apply(T5tokens, meta=('abstract', 'string')).apply(pd.Series, meta=({'input_ids':'object', 'attention_mask':'object'}))\n",
    "\n",
    "# concatenate two dataframes\n",
    "ddf = dd.concat([ddf, ddf2], axis = 1) # create divisions in ddfs? \n",
    "# QA check\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>corpusId</th>\n",
       "      <th>abstract</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=200</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: concat, 208 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                paperId corpusId abstract input_ids attention_mask\n",
       "npartitions=200                                                   \n",
       "                 object   object   object    object         object\n",
       "                    ...      ...      ...       ...            ...\n",
       "...                 ...      ...      ...       ...            ...\n",
       "                    ...      ...      ...       ...            ...\n",
       "                    ...      ...      ...       ...            ...\n",
       "Dask Name: concat, 208 graph layers"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paperId', 'corpusId', 'abstract', 'input_ids', 'attention_mask'], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns for easier reading later\n",
    "ddf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf3.dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save backup\n",
    "# name_function = lambda x: f\"abstracts-{x}.parquet\"\n",
    "# ddf3.to_parquet('/home/ubuntu/work/backup/', name_function = name_function)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Postgresql DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = text(''' \n",
    "#     SELECT EXISTS (\n",
    "#         SELECT FROM information_schema.tables \n",
    "#         WHERE    table_name   = 'abstracts'\n",
    "#     );\n",
    "# ''')\n",
    "\n",
    "# with engine.connect() as conn: \n",
    "#     conn.execute(sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create array columns to store encoding and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = text(''' \n",
    "    DROP TABLE IF EXISTS abstracts_encodings;\n",
    "''')\n",
    "\n",
    "with engine.connect() as conn: \n",
    "    query = conn.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'abstracts_encodings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table\n",
    "# Create Table in DB first before uploading\n",
    "from sqlalchemy import MetaData, Table, Column, Integer, String, ARRAY\n",
    "\n",
    "metadata_obj = MetaData()\n",
    "\n",
    "# Create abstracts metadata\n",
    "abstracts = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"paperId\", String, nullable = True),\n",
    "    Column(\"corpusId\", String, nullable=True),\n",
    "    Column(\"abstract\", String, nullable = True),\n",
    "    Column(\"input_ids\", String, nullable=True),\n",
    "    Column(\"attention_mask\", String, nullable=True),\n",
    ")\n",
    "\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 13 minutes\n",
    "# ddf.to_csv(\"/home/ubuntu/work/backup/abstract_encodings/abstract_encodings-*.csv\",name_function = lambda x: str(x), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "csv_files = glob(\"/home/ubuntu/work/backup/abstract_encodings/*.csv\")\n",
    "# csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "for csv_file_path in csv_files: \n",
    "    with open(csv_file_path, 'r') as f: \n",
    "        df = pd.read_csv(f)\n",
    "        with engine.connect() as conn: \n",
    "            df.to_sql(table_name, con = conn, index = False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dask dataframe to psql\n",
    "# ddf = ddf.to_sql(name = table_name, uri = str(url_object), if_exists = 'replace', index = False, chunksize = 10000, method = 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>corpusId</th>\n",
       "      <th>abstract</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>859c91de1ab22aeff85558dcf676ee5ffc4981a5</td>\n",
       "      <td>33235381</td>\n",
       "      <td>Summary This work aims at applying concepts of...</td>\n",
       "      <td>[20698, 100, 161, 3, 8345, 44, 6247, 6085, 13,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2460a37a3305b3bb072770e5bb57ed95496ecf80</td>\n",
       "      <td>72970529</td>\n",
       "      <td>Summary Objectives: To diagnose the hospital i...</td>\n",
       "      <td>[20698, 27919, 7, 10, 304, 18730, 8, 2833, 251...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e92f481f3be6f0956e0cd6c160a2a384c4eacd76</td>\n",
       "      <td>26375252</td>\n",
       "      <td>Holdoff et al.1 described a retrospective, mon...</td>\n",
       "      <td>[8470, 1647, 3, 15, 17, 491, 5, 536, 3028, 3, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d51f04cfdc8fe907e4a66e948028bf09f3a6af7a</td>\n",
       "      <td>11026954</td>\n",
       "      <td>1. In forty‐one out of forty‐seven dogs under ...</td>\n",
       "      <td>[1300, 86, 19662, 2, 782, 91, 13, 19662, 2, 7,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111d6c65ad374861a3c9c70b210996b76b0a7080</td>\n",
       "      <td>95308098</td>\n",
       "      <td>Calculated and observed excited singlet state ...</td>\n",
       "      <td>[18555, 920, 11, 6970, 2787, 712, 17, 538, 703...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paperId  corpusId  \\\n",
       "0  859c91de1ab22aeff85558dcf676ee5ffc4981a5  33235381   \n",
       "1  2460a37a3305b3bb072770e5bb57ed95496ecf80  72970529   \n",
       "2  e92f481f3be6f0956e0cd6c160a2a384c4eacd76  26375252   \n",
       "3  d51f04cfdc8fe907e4a66e948028bf09f3a6af7a  11026954   \n",
       "4  111d6c65ad374861a3c9c70b210996b76b0a7080  95308098   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Summary This work aims at applying concepts of...   \n",
       "1  Summary Objectives: To diagnose the hospital i...   \n",
       "2  Holdoff et al.1 described a retrospective, mon...   \n",
       "3  1. In forty‐one out of forty‐seven dogs under ...   \n",
       "4  Calculated and observed excited singlet state ...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [20698, 100, 161, 3, 8345, 44, 6247, 6085, 13,...   \n",
       "1  [20698, 27919, 7, 10, 304, 18730, 8, 2833, 251...   \n",
       "2  [8470, 1647, 3, 15, 17, 491, 5, 536, 3028, 3, ...   \n",
       "3  [1300, 86, 19662, 2, 782, 91, 13, 19662, 2, 7,...   \n",
       "4  [18555, 920, 11, 6970, 2787, 712, 17, 538, 703...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if it worked\n",
    "import pandas as pd\n",
    "\n",
    "sql = text(f''' \n",
    "    SELECT * FROM {table_name} LIMIT 5;\n",
    "''')\n",
    "\n",
    "with engine.connect() as conn: \n",
    "    query = conn.execute(sql)\n",
    "\n",
    "test = pd.DataFrame(query.fetchall())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
