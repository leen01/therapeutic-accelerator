{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 02:34:18.266630: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-28 02:34:19.444425: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-28 02:34:19.448373: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-28 02:34:22.404126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, LEDForConditionalGeneration\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration, AutoTokenizer\n",
    "import ast\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from sqlalchemy import create_engine\n",
    "from dask.distributed import Client, LocalCluster, progress\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from glob import glob\n",
    "from rouge_score import rouge_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine to connect to database\n",
    "engine = create_engine(f'postgresql://postgres:qRd71PqwOsbv62WAvboR@database-1.cuaho2dof33c.us-east-1.rds.amazonaws.com:5432/postgres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "/home/ubuntu/anaconda3/envs/ta/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import T5 model\n",
    "\n",
    "T5Abstract_model = TFT5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "T5tokens = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "summary_generator = pipeline(\"summarization\", model=T5Abstract_model, tokenizer=T5tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarize multiple abstracts found within the abstract_encodings table\n",
    "def summarize_multiple_abstracts(list_of_corpusids, tokenizer, t5model, attributes_dataset):\n",
    "  total_input_ids = []\n",
    "  summaries = []\n",
    "  tokenized_summary_prompt = tokenizer.encode(\"summarize: \")\n",
    "  for i in list_of_corpusids:\n",
    "    index_to_use = attributes_dataset[attributes_dataset[\"corpusId\"] == i][\"input_ids\"].index[0]\n",
    "    ids_to_add = ast.literal_eval(attributes_dataset[attributes_dataset[\"corpusId\"] == i][\"input_ids\"][index_to_use])\n",
    "    total_input_ids.append(ids_to_add)\n",
    "  for i in total_input_ids:\n",
    "    tensor_ids = tf.reshape(tf.convert_to_tensor(tokenized_summary_prompt + i), shape=[1, len(tokenized_summary_prompt + i)])\n",
    "    output = t5model.generate(tensor_ids,\n",
    "                              num_beams = 3,\n",
    "                              no_repeat_ngram_size = 3,\n",
    "                              top_k = 10,\n",
    "                              top_p = 70,\n",
    "                              max_length = 200,\n",
    "                              min_length = 70)\n",
    "   # print([tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in output])\n",
    "    summaries.append([tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in output])\n",
    "  return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use T5 summarization on each individual article\n",
    "def abstract_summary_model(corpusid_list):\n",
    "    query = f'''\n",
    "SELECT * FROM abstracts_encodings\n",
    "WHERE \"corpusId\" in {corpusid_list};\n",
    "'''\n",
    "    with engine.connect() as conn:\n",
    "        subset = conn.execute(query)\n",
    "    subset_df = pd.DataFrame(subset.fetchall())\n",
    "    summary_list = summarize_multiple_abstracts(corpusid_list, T5tokens, T5Abstract_model, subset_df)\n",
    "    return summary_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 02:35:14.525971: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x23a532a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-28 02:35:14.526028: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Host, Default Version\n",
      "2023-07-28 02:35:14.733475: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-28 02:35:15.439991: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CorpusID</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>ROUGE1 Percision</th>\n",
       "      <th>ROUGE1 Recal</th>\n",
       "      <th>ROUGE1 F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231926055</td>\n",
       "      <td>present two cases of nervus intermedius neural...</td>\n",
       "      <td>Present two cases of nervus intermedius neural...</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7465525</td>\n",
       "      <td>chromosome territories (CTs) have been conserv...</td>\n",
       "      <td>We demonstrate that the nuclear topological ar...</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.156069</td>\n",
       "      <td>0.255924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143460832</td>\n",
       "      <td>the degree of reproducibility of treatment eff...</td>\n",
       "      <td>The data of the Collaborative Behavioral Terat...</td>\n",
       "      <td>0.062785</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.218905</td>\n",
       "      <td>0.345098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253396535</td>\n",
       "      <td>high rates of asymptomatic and mild infections...</td>\n",
       "      <td>Background Coronavirus Disease 2019 (COVID-19)...</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.132597</td>\n",
       "      <td>0.232446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55052301</td>\n",
       "      <td>375 medial UKAs were analyzed in a large multi...</td>\n",
       "      <td>Introduction: We sought to compare outcomes, c...</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.327586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>42916569</td>\n",
       "      <td>congenital central hypoventilation syndrome su...</td>\n",
       "      <td>OBJECTIVE. Individuals with congenital central...</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.188235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>38215235</td>\n",
       "      <td>aims were to assess the evidence that individu...</td>\n",
       "      <td>The aims were to assess the evidence that indi...</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>220666170</td>\n",
       "      <td>luciferase analysis confirms the interaction b...</td>\n",
       "      <td>Background: Long noncoding RNAs are involved i...</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.137566</td>\n",
       "      <td>0.228070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>73653310</td>\n",
       "      <td>FecB mutation enhances ovulation rate and in t...</td>\n",
       "      <td>High prolificacy in Garole sheep is due to exi...</td>\n",
       "      <td>0.067912</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.390041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>46697602</td>\n",
       "      <td>the first international meeting of ophthalmolo...</td>\n",
       "      <td>Society was formed on May 30th and 31st, 1908....</td>\n",
       "      <td>0.007229</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0.253219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CorpusID                                            Summary  \\\n",
       "0   231926055  present two cases of nervus intermedius neural...   \n",
       "1     7465525  chromosome territories (CTs) have been conserv...   \n",
       "2   143460832  the degree of reproducibility of treatment eff...   \n",
       "3   253396535  high rates of asymptomatic and mild infections...   \n",
       "4    55052301  375 medial UKAs were analyzed in a large multi...   \n",
       "..        ...                                                ...   \n",
       "95   42916569  congenital central hypoventilation syndrome su...   \n",
       "96   38215235  aims were to assess the evidence that individu...   \n",
       "97  220666170  luciferase analysis confirms the interaction b...   \n",
       "98   73653310  FecB mutation enhances ovulation rate and in t...   \n",
       "99   46697602  the first international meeting of ophthalmolo...   \n",
       "\n",
       "                                             Abstract      BLEU  \\\n",
       "0   Present two cases of nervus intermedius neural...  0.630435   \n",
       "1   We demonstrate that the nuclear topological ar...  0.024647   \n",
       "2   The data of the Collaborative Behavioral Terat...  0.062785   \n",
       "3   Background Coronavirus Disease 2019 (COVID-19)...  0.002821   \n",
       "4   Introduction: We sought to compare outcomes, c...  0.016824   \n",
       "..                                                ...       ...   \n",
       "95  OBJECTIVE. Individuals with congenital central...  0.002352   \n",
       "96  The aims were to assess the evidence that indi...  0.629630   \n",
       "97  Background: Long noncoding RNAs are involved i...  0.010085   \n",
       "98  High prolificacy in Garole sheep is due to exi...  0.067912   \n",
       "99  Society was formed on May 30th and 31st, 1908....  0.007229   \n",
       "\n",
       "    ROUGE1 Percision  ROUGE1 Recal  ROUGE1 F1  \n",
       "0           0.622222      0.933333   0.746667  \n",
       "1           0.710526      0.156069   0.255924  \n",
       "2           0.814815      0.218905   0.345098  \n",
       "3           0.941176      0.132597   0.232446  \n",
       "4           0.904762      0.200000   0.327586  \n",
       "..               ...           ...        ...  \n",
       "95          0.727273      0.108108   0.188235  \n",
       "96          0.611111      0.916667   0.733333  \n",
       "97          0.666667      0.137566   0.228070  \n",
       "98          0.903846      0.248677   0.390041  \n",
       "99          0.893939      0.147500   0.253219  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate summaries based on random papers\n",
    "sql = f'''\n",
    "SELECT * from abstracts order by random() limit 100\n",
    "\n",
    "'''\n",
    "with engine.connect() as conn:\n",
    "    query = conn.execute(text(sql))\n",
    "    \n",
    "df = pd.DataFrame(query.fetchall())\n",
    "\n",
    "corp_id_list = [int(i) for i in df['corpusId'].to_list()]\n",
    "corpusid_list = tuple([str(i) for i in corp_id_list])\n",
    "\n",
    "sum_list = abstract_summary_model(corpusid_list)\n",
    "\n",
    "#create dataframe to log results\n",
    "df_scores = pd.DataFrame(columns = [\"CorpusID\", \"Summary\", \"Abstract\",\"BLEU\",\"ROUGE1 Percision\", \"ROUGE1 Recal\", \"ROUGE1 F1\"])\n",
    "\n",
    "#compare summaries to abstracts and calculate scores\n",
    "for i in range(0,len(corp_id_list)):\n",
    "\n",
    "    corp_id = corp_id_list[i]\n",
    "\n",
    "    sql = f''' \n",
    "        SELECT * FROM abstracts WHERE \"corpusId\" = '{corp_id}';\n",
    "    '''\n",
    "\n",
    "    with engine.connect() as conn: \n",
    "        query = conn.execute(sql)\n",
    "\n",
    "    df = pd.DataFrame(query.fetchall())\n",
    "\n",
    "    reference = df['abstract'][0]\n",
    "    candidate = sum_list[i][0]\n",
    "\n",
    "    bleu = (sentence_bleu([reference.split()], candidate.split() , weights=[1]))\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"],  use_stemmer=True )\n",
    "    rouge_scorer_obj =(scorer.score(reference, candidate))\n",
    "\n",
    "    r_percision = rouge_scorer_obj['rouge2'][0]\n",
    "    r_recall = rouge_scorer_obj['rouge2'][1]\n",
    "    r_f1 = rouge_scorer_obj['rouge2'][2]\n",
    "\n",
    "    row = [corp_id, candidate, reference, bleu, r_percision, r_recall, r_f1]\n",
    "    df_scores.loc[len(df_scores)] = row\n",
    "\n",
    "df_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40675152117915414\n",
      "0.3077974242629597\n",
      "0.853749364242686\n",
      "0.15601992830569855\n"
     ]
    }
   ],
   "source": [
    "print (df_scores['ROUGE1 F1'].mean())\n",
    "print (df_scores['ROUGE1 Recal'].mean())\n",
    "print (df_scores['ROUGE1 Percision'].mean())\n",
    "print (df_scores['BLEU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3978287654140744\n"
     ]
    }
   ],
   "source": [
    "df_scores['Summary Len'] = df_scores['Summary'].str.len()\n",
    "df_scores['Abstract Len'] = df_scores['Abstract'].str.len()\n",
    "df_scores['reduction'] = df_scores['Summary Len']/df_scores['Abstract Len']\n",
    "print (df_scores['reduction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
